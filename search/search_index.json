{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"EloGrad","text":"<p>Extended Elo rating system implementation exploiting the equivalence with logistic regression.</p> <p>EloGrad (Elo as Gradient descent) leverages the framing of the  Elo rating system as logistic regression with stochastic gradient descent (see this blog for a nice walkthrough) to offer a collection of extensions to the rating system. All models are <code>scikit-learn</code> compatible.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install <code>elo-grad</code> with: <pre><code>pip install elo-grad\n</code></pre></p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Detailed example notebooks are provided in the <code>examples/</code> directory. To install any extra dependencies required to run the notebooks install with: <pre><code>pip install elo-grad[examples]\n</code></pre></p>"},{"location":"#minimal-example","title":"Minimal Example","text":"<pre><code>from elo_grad import EloEstimator\n\n# Input DataFrame with sorted index of Unix timestamps\n# and columns entity_1 | entity_2 | score\n# where score = 1 if player_1 won and score = 0 if\n# player_2 won.\ndf = ...\nestimator = EloEstimator(\n    k_factor=20, \n    default_init_rating=1200,\n    entity_cols=(\"player_1\", \"player_2\"),\n    score_col=\"result\",\n)\n# Get expected scores\nexpected_scores = estimator.predict_proba(df)\n# Get final ratings (of form (Unix timestamp, rating))\nratings = estimator.model.ratings\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<p>In rough order, things we want to add are: - Poisson model support - Regularization (L1 &amp; L2) - Support for Polars - Head-to-head ratings - Interaction terms - Other optimizers, e.g. momentum - Support for draws - Extend plotting support, e.g. plotly</p>"},{"location":"#references","title":"References","text":"<ol> <li>Elo rating system: https://en.wikipedia.org/wiki/Elo_rating_system</li> <li>Elo rating system as logistic regression with stochastic gradient descent: https://stmorse.github.io/journal/Elo.html</li> <li>Elo rating system for NFL predictions: https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/</li> </ol>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#elo_grad.EloEstimator","title":"<code>EloEstimator</code>","text":"<p>               Bases: <code>HistoryPlotterMixin</code>, <code>RatingSystemMixin</code>, <code>BaseEstimator</code></p> <p>Elo rating system classifier.</p> <p>Attributes:</p> Name Type Description <code>beta</code> <code>float</code> <p>Normalization factor for ratings when computing expected score.</p> <code>columns</code> <code>List[str]</code> <p>[entity_1, entity_2, result] columns names.</p> <code>default_init_rating</code> <code>float</code> <p>Default initial rating for entities.</p> <code>entity_cols</code> <code>Tuple[str, str]</code> <p>Names of columns identifying the names of the entities playing the games.</p> <code>init_ratings</code> <code>Optional[Dict[str, Tuple[Optional[int], float]]]</code> <p>Initial ratings for entities (dictionary of form entity: (Unix timestamp, rating))</p> <code>k_factor</code> <code>float</code> <p>Elo K-factor/step-size for gradient descent.</p> <code>k_factor_vec</code> <code>Tuple[float, ...]</code> <p>Vector of Elo K-factor/step-size for gradient descent.</p> <code>model</code> <code>Model</code> <p>Underlying statistical model.</p> <code>optimizer</code> <code>Optimizer</code> <p>Optimizer to update the model.</p> <code>rating_history</code> <code>List[Tuple[Optional[int], float]]</code> <p>Historical ratings of entities (if track_rating_history is True).</p> <code>score_col</code> <code>str</code> <p>Name of score column (1 if entity_1 wins and 0 if entity_2 wins). Draws are not currently supported.</p> <code>additional_regressors</code> <code>Optional[List[Regressor]]</code> <p>Additional regressors to include, e.g. home advantage.</p> <code>track_rating_history</code> <code>bool</code> <p>Flag to track historical ratings of entities.</p> <p>Methods:</p> Name Description <code>fit</code> <p>Fit Elo rating system/calculate ratings.</p> <code>record_ratings</code> <p>Record the current ratings of entities.</p> <code>predict_proba</code> <p>Produce probability estimates.</p> <code>predict</code> <p>Predict outcome of game.</p> Source code in <code>src/elo_grad/__init__.py</code> <pre><code>class EloEstimator(HistoryPlotterMixin, RatingSystemMixin, BaseEstimator):\n    \"\"\"\n    Elo rating system classifier.\n\n    Attributes\n    ----------\n    beta : float\n        Normalization factor for ratings when computing expected score.\n    columns : List[str]\n        [entity_1, entity_2, result] columns names.\n    default_init_rating : float\n        Default initial rating for entities.\n    entity_cols : Tuple[str, str]\n        Names of columns identifying the names of the entities playing the games.\n    init_ratings : Optional[Dict[str, Tuple[Optional[int], float]]]\n        Initial ratings for entities (dictionary of form entity: (Unix timestamp, rating))\n    k_factor : float\n        Elo K-factor/step-size for gradient descent.\n    k_factor_vec : Tuple[float, ...]\n        Vector of Elo K-factor/step-size for gradient descent.\n    model : Model\n        Underlying statistical model.\n    optimizer : Optimizer\n        Optimizer to update the model.\n    rating_history : List[Tuple[Optional[int], float]]\n        Historical ratings of entities (if track_rating_history is True).\n    score_col : str\n        Name of score column (1 if entity_1 wins and 0 if entity_2 wins).\n        Draws are not currently supported.\n    additional_regressors : Optional[List[Regressor]]\n        Additional regressors to include, e.g. home advantage.\n    track_rating_history : bool\n        Flag to track historical ratings of entities.\n\n    Methods\n    -------\n    fit(X, y=None)\n        Fit Elo rating system/calculate ratings.\n    record_ratings()\n        Record the current ratings of entities.\n    predict_proba(X)\n        Produce probability estimates.\n    predict(X)\n        Predict outcome of game.\n    \"\"\"\n\n    def __init__(\n        self,\n        k_factor: float = 20,\n        default_init_rating: float = 1200,\n        beta: float = 200,\n        init_ratings: Optional[Dict[str, Tuple[Optional[int], float]]] = None,\n        entity_cols: Tuple[str, str] = (\"entity_1\", \"entity_2\"),\n        score_col: str = \"score\",\n        additional_regressors: Optional[List[Regressor]] = None,\n        track_rating_history: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Parameters\n        ----------\n        k_factor : float\n            Elo K-factor/step-size for gradient descent for the entities.\n        default_init_rating : float\n            Default initial rating for entities.\n        beta : float\n            Normalization factor for ratings when computing expected score.\n        init_ratings : Optional[Dict[str, Tuple[Optional[int], float]]]\n            Initial ratings for entities (dictionary of form entity: (Unix timestamp, rating))\n        entity_cols : Tuple[str, str]\n            Names of columns identifying the names of the entities playing the games.\n        score_col : str\n            Name of score column (1 if entity_1 wins and 0 if entity_2 wins).\n            Draws are not currently supported.\n        additional_regressors : Optional[List[Regressor]]\n            Additional regressors to include, e.g. home advantage.\n        track_rating_history : bool\n            Flag to track historical ratings of entities.\n        \"\"\"\n        self.entity_cols: Tuple[str, str] = entity_cols\n        self.score_col: str = score_col\n        self.columns: List[str] = list(entity_cols) + [score_col]\n        self.beta: float = beta\n        self.default_init_rating: float = default_init_rating\n        self.init_ratings: Optional[Dict[str, Tuple[Optional[int], float]]] = init_ratings\n        self.model: Model = LogisticRegression(\n            beta=beta,\n            default_init_rating=default_init_rating,\n            init_ratings=init_ratings,\n        )\n        self.additional_regressors: List[Regressor] = additional_regressors if additional_regressors is not None else []\n        if additional_regressors is not None:\n            self.columns.extend([r.name for r in additional_regressors])\n        self.k_factor: float = k_factor\n        self.k_factor_vec: Tuple[float, ...] = (\n            k_factor,\n            *(r.k_factor if r.k_factor is not None else k_factor for r in self.additional_regressors),\n        )\n        self.optimizer: Optimizer = SGDOptimizer(k_factor=self.k_factor_vec)\n        self.track_rating_history: bool = track_rating_history\n        self.rating_history: List[Tuple[Optional[int], float]] = defaultdict(list)  # type:ignore\n\n    @staticmethod\n    def _reinitialize_rating_system(method: Callable):\n        \"\"\"\n        Decorator to reinitialize the rating system after parameter changes.\n        Helpful when peforming a grid search.\n\n        Parameters\n        ----------\n        method : Callable\n            Method to decorate\n        \"\"\"\n\n        def wrapper(self, **params):\n            result = method(self, **params)\n            self.model = LogisticRegression(\n                beta=self.beta,\n                default_init_rating=self.default_init_rating,\n                init_ratings=self.init_ratings,\n            )\n            self.k_factor_vec = (\n                self.k_factor,\n                *(r.k_factor if r.k_factor is not None else self.k_factor for r in self.additional_regressors),\n            )\n            self.optimizer = SGDOptimizer(k_factor=self.k_factor_vec)\n\n            return result\n\n        return wrapper\n\n    @_reinitialize_rating_system\n    def set_params(self, **params):\n        return super().set_params(**params)\n\n    def _update_ratings(self, t: int, rating_deltas: Dict[str, float]) -&gt; None:\n        for entity in rating_deltas:\n            self.model.ratings[entity] = (t, self.model.ratings[entity][1] + rating_deltas[entity])\n\n    def record_ratings(self) -&gt; None:\n        \"\"\"\n        Record the current ratings of entities.\n        \"\"\"\n        for k, v in self.model.ratings.items():\n            self.rating_history[k].append(v)  # type:ignore\n\n    def _transform(self, X: pd.DataFrame, return_expected_score: bool) -&gt; Optional[np.ndarray]:\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"X must be a pandas DataFrame.\")\n        X = X[self.columns]\n\n        if not X.index.is_monotonic_increasing:\n            raise ValueError(\"Index must be sorted.\")\n        current_ix: int = X.index[0]\n\n        additional_regressor_flag: bool = len(self.additional_regressors) &gt; 0\n        additional_regressor_contrib: float = 0.0\n        additional_regressor_values: Optional[Tuple[float, ...]] = None\n        preds = array(\"f\") if return_expected_score else None\n        rating_deltas: Dict[str, float] = defaultdict(float)\n        for row in X.itertuples(index=True):\n            if additional_regressor_flag:\n                ix, entity_1, entity_2, score, *additional_regressor_values = row\n            else:\n                ix, entity_1, entity_2, score = row\n\n            if ix != current_ix:\n                self._update_ratings(ix, rating_deltas)\n                current_ix, rating_deltas = ix, defaultdict(float)\n                if self.track_rating_history:\n                    self.record_ratings()\n\n            if additional_regressor_flag:\n                additional_regressor_contrib = sum(\n                    self.model.ratings[k.name][1] * v  # type:ignore\n                    for k, v in zip(self.additional_regressors, additional_regressor_values)  # type:ignore\n                )\n\n            expected_score: float = self.model.calculate_expected_score(\n                self.model.ratings[entity_1][1],\n                -self.model.ratings[entity_2][1],\n                additional_regressor_contrib,\n            )\n            if return_expected_score:\n                preds.append(expected_score)  # type:ignore\n\n            _rating_deltas: Generator[float, None, None] = self.optimizer.calculate_update_step(\n                model=self.model,\n                y=score,\n                entity_1=entity_1,\n                entity_2=entity_2,\n                regressor_contrib=additional_regressor_contrib,\n                regressor_values=additional_regressor_values,\n            )\n            entity_update: float = next(_rating_deltas)\n            rating_deltas[entity_1] += entity_update\n            rating_deltas[entity_2] -= entity_update\n            if additional_regressor_flag:\n                for r in self.additional_regressors:\n                    rating_deltas[r.name] += next(_rating_deltas)\n\n        self._update_ratings(ix, rating_deltas)\n        if self.track_rating_history:\n            self.record_ratings()\n\n        if return_expected_score:\n            return np.array(preds)\n        return None\n\n    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None):\n        self._transform(X, return_expected_score=False)\n        return self\n\n    def predict_proba(self, X: pd.DataFrame) -&gt; np.ndarray:\n        preds = self._transform(X, return_expected_score=True)\n        return np.vstack((1 - preds, preds)).T  # type:ignore\n\n    def predict(self, X: pd.DataFrame) -&gt; np.ndarray:\n        return self.predict_proba(X)[:, 1] &gt; 0.5\n</code></pre>"},{"location":"api/#elo_grad.EloEstimator.__init__","title":"<code>__init__(k_factor=20, default_init_rating=1200, beta=200, init_ratings=None, entity_cols=('entity_1', 'entity_2'), score_col='score', additional_regressors=None, track_rating_history=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>k_factor</code> <code>float</code> <p>Elo K-factor/step-size for gradient descent for the entities.</p> <code>20</code> <code>default_init_rating</code> <code>float</code> <p>Default initial rating for entities.</p> <code>1200</code> <code>beta</code> <code>float</code> <p>Normalization factor for ratings when computing expected score.</p> <code>200</code> <code>init_ratings</code> <code>Optional[Dict[str, Tuple[Optional[int], float]]]</code> <p>Initial ratings for entities (dictionary of form entity: (Unix timestamp, rating))</p> <code>None</code> <code>entity_cols</code> <code>Tuple[str, str]</code> <p>Names of columns identifying the names of the entities playing the games.</p> <code>('entity_1', 'entity_2')</code> <code>score_col</code> <code>str</code> <p>Name of score column (1 if entity_1 wins and 0 if entity_2 wins). Draws are not currently supported.</p> <code>'score'</code> <code>additional_regressors</code> <code>Optional[List[Regressor]]</code> <p>Additional regressors to include, e.g. home advantage.</p> <code>None</code> <code>track_rating_history</code> <code>bool</code> <p>Flag to track historical ratings of entities.</p> <code>False</code> Source code in <code>src/elo_grad/__init__.py</code> <pre><code>def __init__(\n    self,\n    k_factor: float = 20,\n    default_init_rating: float = 1200,\n    beta: float = 200,\n    init_ratings: Optional[Dict[str, Tuple[Optional[int], float]]] = None,\n    entity_cols: Tuple[str, str] = (\"entity_1\", \"entity_2\"),\n    score_col: str = \"score\",\n    additional_regressors: Optional[List[Regressor]] = None,\n    track_rating_history: bool = False,\n) -&gt; None:\n    \"\"\"\n    Parameters\n    ----------\n    k_factor : float\n        Elo K-factor/step-size for gradient descent for the entities.\n    default_init_rating : float\n        Default initial rating for entities.\n    beta : float\n        Normalization factor for ratings when computing expected score.\n    init_ratings : Optional[Dict[str, Tuple[Optional[int], float]]]\n        Initial ratings for entities (dictionary of form entity: (Unix timestamp, rating))\n    entity_cols : Tuple[str, str]\n        Names of columns identifying the names of the entities playing the games.\n    score_col : str\n        Name of score column (1 if entity_1 wins and 0 if entity_2 wins).\n        Draws are not currently supported.\n    additional_regressors : Optional[List[Regressor]]\n        Additional regressors to include, e.g. home advantage.\n    track_rating_history : bool\n        Flag to track historical ratings of entities.\n    \"\"\"\n    self.entity_cols: Tuple[str, str] = entity_cols\n    self.score_col: str = score_col\n    self.columns: List[str] = list(entity_cols) + [score_col]\n    self.beta: float = beta\n    self.default_init_rating: float = default_init_rating\n    self.init_ratings: Optional[Dict[str, Tuple[Optional[int], float]]] = init_ratings\n    self.model: Model = LogisticRegression(\n        beta=beta,\n        default_init_rating=default_init_rating,\n        init_ratings=init_ratings,\n    )\n    self.additional_regressors: List[Regressor] = additional_regressors if additional_regressors is not None else []\n    if additional_regressors is not None:\n        self.columns.extend([r.name for r in additional_regressors])\n    self.k_factor: float = k_factor\n    self.k_factor_vec: Tuple[float, ...] = (\n        k_factor,\n        *(r.k_factor if r.k_factor is not None else k_factor for r in self.additional_regressors),\n    )\n    self.optimizer: Optimizer = SGDOptimizer(k_factor=self.k_factor_vec)\n    self.track_rating_history: bool = track_rating_history\n    self.rating_history: List[Tuple[Optional[int], float]] = defaultdict(list)  # type:ignore\n</code></pre>"},{"location":"api/#elo_grad.EloEstimator.record_ratings","title":"<code>record_ratings()</code>","text":"<p>Record the current ratings of entities.</p> Source code in <code>src/elo_grad/__init__.py</code> <pre><code>def record_ratings(self) -&gt; None:\n    \"\"\"\n    Record the current ratings of entities.\n    \"\"\"\n    for k, v in self.model.ratings.items():\n        self.rating_history[k].append(v)  # type:ignore\n</code></pre>"},{"location":"api/#elo_grad.RatingSystemMixin","title":"<code>RatingSystemMixin</code>","text":"<p>Mixin class for rating systems.</p> <p>This mixin defines the following functionality:</p> <ul> <li><code>_estimator_type</code> class attribute defaulting to <code>\"rating-system\"</code>;</li> <li><code>score</code> method that default to :func:<code>~sklearn.metrics.log_loss</code>.</li> <li>enforce that <code>fit</code> does not require <code>y</code> to be passed through the <code>requires_y</code> tag.</li> </ul> <p>Read more in the :ref:<code>User Guide &lt;rolling_your_own_estimator&gt;</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sklearn.base import BaseEstimator\n&gt;&gt;&gt; from elo_grad import RatingSystemMixin\n&gt;&gt;&gt; # Mixin classes should always be on the left-hand side for a correct MRO\n&gt;&gt;&gt; class MyEstimator(RatingSystemMixin, BaseEstimator):\n...     def __init__(self, *, param=1):\n...         self.param = param\n...     def fit(self, X, y=None):\n...         self.is_fitted_ = True\n...         return self\n...     def predict(self, X):\n...         return np.full(shape=X.shape[0], fill_value=self.param)\n&gt;&gt;&gt; estimator = MyEstimator(param=1)\n&gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]])\n&gt;&gt;&gt; y = np.array([1, 0, 1])\n&gt;&gt;&gt; estimator.fit(X, y).predict(X)\narray([1, 1, 1])\n&gt;&gt;&gt; estimator.score(X, y)\n0.66...\n</code></pre> Source code in <code>src/elo_grad/__init__.py</code> <pre><code>class RatingSystemMixin:\n    \"\"\"\n    Mixin class for rating systems.\n\n    This mixin defines the following functionality:\n\n    - `_estimator_type` class attribute defaulting to `\"rating-system\"`;\n    - `score` method that default to :func:`~sklearn.metrics.log_loss`.\n    - enforce that `fit` does not require `y` to be passed through the `requires_y` tag.\n\n    Read more in the :ref:`User Guide &lt;rolling_your_own_estimator&gt;`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from sklearn.base import BaseEstimator\n    &gt;&gt;&gt; from elo_grad import RatingSystemMixin\n    &gt;&gt;&gt; # Mixin classes should always be on the left-hand side for a correct MRO\n    &gt;&gt;&gt; class MyEstimator(RatingSystemMixin, BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    &gt;&gt;&gt; estimator = MyEstimator(param=1)\n    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]])\n    &gt;&gt;&gt; y = np.array([1, 0, 1])\n    &gt;&gt;&gt; estimator.fit(X, y).predict(X)\n    array([1, 1, 1])\n    &gt;&gt;&gt; estimator.score(X, y)\n    0.66...\n    \"\"\"\n\n    _estimator_type = \"classifier\"\n    classes_ = [[0, 1]]\n\n    def score(self, X, y, sample_weight=None):\n        \"\"\"\n        Return the log-loss on the given test data and labels.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n        \"\"\"\n        return log_loss(\n            y, self.predict_proba(X)[:, 1], sample_weight=sample_weight\n        )\n\n    def _more_tags(self):\n        return {\"requires_y\": False}\n</code></pre>"},{"location":"api/#elo_grad.RatingSystemMixin.score","title":"<code>score(X, y, sample_weight=None)</code>","text":"<p>Return the log-loss on the given test data and labels.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array-like of shape (n_samples, n_features)</code> <p>Test samples.</p> required <code>y</code> <code>array-like of shape (n_samples,) or (n_samples, n_outputs)</code> <p>True labels for <code>X</code>.</p> required <code>sample_weight</code> <code>array-like of shape (n_samples,)</code> <p>Sample weights.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>float</code> <p>Mean accuracy of <code>self.predict(X)</code> w.r.t. <code>y</code>.</p> Source code in <code>src/elo_grad/__init__.py</code> <pre><code>def score(self, X, y, sample_weight=None):\n    \"\"\"\n    Return the log-loss on the given test data and labels.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Test samples.\n\n    y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        True labels for `X`.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights.\n\n    Returns\n    -------\n    score : float\n        Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n    \"\"\"\n    return log_loss(\n        y, self.predict_proba(X)[:, 1], sample_weight=sample_weight\n    )\n</code></pre>"},{"location":"api/#elo_grad.Regressor","title":"<code>Regressor</code>  <code>dataclass</code>","text":"<p>Regressor (additional) to entities.</p> <p>name : str     Name of regressor column in dataset. k_factor : Optional[float]     k-factor for this regressor's dimension. If None, the global k-factor for entities is used. lambda_reg : Optional[float]     Regularisation parameter for regressor model coefficient, if L1 or L2 regularisation is used.</p> Source code in <code>src/elo_grad/__init__.py</code> <pre><code>@dataclass(frozen=True)\nclass Regressor:\n    \"\"\"\n    Regressor (additional) to entities.\n\n    name : str\n        Name of regressor column in dataset.\n    k_factor : Optional[float]\n        k-factor for this regressor's dimension. If None, the global k-factor for entities is used.\n    lambda_reg : Optional[float]\n        Regularisation parameter for regressor model coefficient, if L1 or L2 regularisation is used.\n    \"\"\"\n    name: str\n    k_factor: Optional[float] = None\n    lambda_reg: Optional[float] = None\n</code></pre>"},{"location":"intro/","title":"Elo as Logistic Regression","text":"<p>EloGrad is motivated by the framing of the Elo rating system as logistic regression with gradient descent, and the natural extensions to the rating system that arise from that. We derive that relationship here.</p> <p>In <code>elo-grad</code>, we implement the Elo rating system as logistic regression with mini-batch gradient descent,  where batches are defined by date rather than stochastic gradient descent.</p>"},{"location":"intro/#elo-rating-system","title":"Elo Rating System","text":"<p>In the Elo rating system, we have a set of entities, \\(i=1,\\cdots,n\\), with corresponding ratings \\(r_1,\\cdots,r_n\\). The expected score/outcome of a game between entities \\(i\\) and \\(j\\) is given by $$ \\begin{equation} \\mathbb{E}[y_{ij}|r_1,\\cdots,r_n] = \\frac{1}{1 + 10^{-(r_i - r_j) / 2\\beta}}, \\end{equation} $$ where \\(\\beta\\) is a normalisation factor and \\(y_{ij}\\) is the score/outcome of a game between entity \\(i\\) and \\(j\\): $$ \\begin{equation} y_{ij} =  \\begin{cases} 1 &amp; \\text{if}\\,i\\,\\text{wins}, \\\\ 0 &amp; \\text{if}\\,j\\,\\text{wins}. \\end{cases} \\end{equation} $$ NOTE: we are restricting ourselves to a binary outcome.</p> <p>After a game, each entity's rating is updated as $$ \\begin{equation} r^\\prime_i=r_i + k \\left(y_{ij} - \\mathbb{E}[y_{ij}|r_1,\\cdots,r_n]\\right), \\end{equation} $$ where \\(k\\) is the k-factor. </p>"},{"location":"intro/#logistic-regression","title":"Logistic Regression","text":"<p>Suppose we have a binary outcome \\(y|\\mathbf{x}\\sim\\text{Bernoulli}(p)\\), where \\(\\mathbf{x}\\) is the set of input variables/regressors and \\(p\\) is the outcome probability. If we model this outcome with model parameters \\(\\mathbf{w}\\), the likelihood function is given by $$ \\begin{equation} \\mathcal{L}(\\mathbf{w})= p(y|\\mathbf{w};\\mathbf{x})^y\\left(1-p(y|\\mathbf{w};\\mathbf{x})\\right)^{1-y}. \\end{equation} $$</p> <p>The logistic regression model (with base 10) assumes the outcome probability is given by $$ \\begin{equation} p(y|\\mathbf{w};\\mathbf{x})= \\frac{1}{1 + 10^{-\\mathbf{w}\\cdot\\mathbf{x}}}. \\end{equation} $$ We have not included an intercept.</p> <p>Suppose each observation corresponds to a game between two of \\(n\\) entities and we have one regressor for each entity. For each game we (arbitrarily) define an order for the entities - let the first entity be denoted by \\(i\\) and the second by \\(j\\). For each game, the regressor corresponding to entity \\(i\\) takes value \\(1\\) and the regressor corresponding to entity \\(j\\) takes value \\(-1\\). Regressors corresponding to other entities take value \\(0\\). We can represent this as</p> \\[ \\begin{equation} \\mathbf{x}_k=\\delta_{ik} - \\delta_{jk}, \\end{equation} \\] <p>where \\(\\delta_{ij}\\) is the Kronecker delta.</p> <p>The table below shows how the data would look like for two games:</p> <ul> <li>team \\(1\\) beats team \\(2\\) on 01/01/24,</li> <li>team \\(n\\) beats team \\(1\\) on 02/01/24.</li> </ul> Date y Team 1 Team 2 Team 3 ... Team n 01/01/24 1 1 -1 0 ... 0 02/01/24 0 -1 0 0 ... 1 ... ... ... ... ... ... ... <p>We can equivalently represent the games as</p> Date y Team 1 Team 2 Team 3 ... Team n 01/01/24 0 -1 1 0 ... 0 02/01/24 1 1 0 0 ... -1 ... ... ... ... ... ... ... <p>i.e. flipping the outcome variable and changing the sign of the regressors.</p> <p>With the regressors described above, we can rewrite (5) as $$ \\begin{equation} p(y_{ij}|\\mathbf{w};\\mathbf{x})= \\frac{1}{1 + 10^{-(w_i - w_j)}}, \\end{equation} $$ where, as in (2), \\(y_{ij}\\) represents the score/outcome of a game between team \\(i\\) and \\(j\\). If we define \\(r_i:=w_i/2\\beta\\) then we recover the Elo expected score/outcome equation (1).</p>"},{"location":"intro/#stochastic-gradient-descent","title":"Stochastic Gradient Descent","text":"<p>Stochastic gradient descent (SGD) is a commonly used optimisation method. It is an approximation of gradient descent  and can be used to perform maximum likelihood estimation (MLE) for logistic regression. SGD approximates the gradient descent process by updating parameters based on one sample at time (or a small set of samples at a time, which is sometimes called mini-batch gradient descent). This is typically used when it is computationally infeasible to fit the model using all samples at once.</p> <p>Gradient descent identifies the direction in parameter space in which a loss function decreases fastest. It updates the parameters by stepping in this direction. We can write this as $$ \\begin{equation} \\mathbf{w}^t=\\mathbf{w}^{t-1} - \\alpha\\nabla_{\\mathbf{w}} L, \\end{equation} $$ where \\(L\\) is the loss function to be optimized, \\(\\alpha\\) is the step size, \\(\\mathbf{w}^t\\) are the model parameters at step \\(t\\) and \\(\\nabla_{\\mathbf{w}}\\) is the gradient with respect to the model parameters.</p> <p>The update method for SGD is given by $$ \\begin{equation} \\mathbf{w}^t=\\mathbf{w}^{t-1} - \\alpha\\nabla_{\\mathbf{w}}^{a} L, \\end{equation} $$ where \\(\\nabla_{\\mathbf{w}}^{a}\\) is the gradient with respect to the model parameters,  evaluated for observation \\(a\\) which is usually randomly selected. For mini-batch gradient descent, \\(a\\) represents a set of samples.</p>"},{"location":"intro/#sgd-for-logistic-regression","title":"SGD for Logistic Regression","text":"<p>We can perform gradient descent for logistic regression by minimising the negative log-likelihood. The gradient of the negative log likelihood for logistic regression is given by $$ \\begin{align} \\nabla_{\\mathbf{w}}\\mathcal l &amp;= -\\sum_a \\left[ y_a \\frac{\\nabla_{\\mathbf{w}}p(y|\\mathbf{w};\\mathbf{x})}{p(y|\\mathbf{w};\\mathbf{x})} -\\frac{(1 - y_a)(\\nabla_{\\mathbf{w}}p(y|\\mathbf{w};\\mathbf{x})}{1 - p(y|\\mathbf{w};\\mathbf{x})} \\right],\\\\ &amp;=-\\sum_a\\left[ y_a(1 - p(y|\\mathbf{w};\\mathbf{x})) - (1 - y_a)p(y|\\mathbf{w};\\mathbf{x})) \\right]\\mathbf{x},\\\\ &amp;=\\sum_a\\left[p(y|\\mathbf{w};\\mathbf{x}) - y_a\\right]\\mathbf{x}, \\end{align} $$ where \\(p(y|\\mathbf{w};\\mathbf{x})\\) is the logistic function (5), \\(l\\) is the negative log-likelihood and \\(a\\) runs over the set of observations/games.</p> <p>The update method for the model parameters is then given by $$ \\begin{equation} \\mathbf{w}^t =\\mathbf{w}^{t-1} + \\alpha \\sum_a \\left(y_a - p(y|\\mathbf{w};\\mathbf{x})\\right). \\end{equation} $$</p> <p>If we have the regressors described in the Logistic Regression section above and restrict ourselves to stochastic gradient descent,  this becomes $$ \\begin{equation} \\mathbf{w}^t =\\mathbf{w}^{t-1} + \\alpha \\left(y_{ij} - \\frac{1}{1 + 10^{-(w_i - w_j)}}\\right). \\end{equation} $$ Defining \\(r_i:=w_i/2\\beta\\), becomes $$ \\begin{equation} \\mathbf{r}^t =\\mathbf{r}^{t-1} + 2\\alpha\\beta \\left(y_{ij} - \\frac{1}{1 + 10^{-(r_i - r_j) / 2\\beta}}\\right). \\end{equation} $$ Defining \\(k:=2\\alpha\\beta\\), we recover (3) and the Elo rating system.</p>"},{"location":"feature_ref/additional_regressors/","title":"Additional Regressors","text":"<p>Having framed the Elo rating system as logistic regression with stochastic gradient descent (see Elo as Logistic Regression) it is straightforward to add additional regressors. We modify (1) from Elo as Logistic Regression as $$ \\begin{equation} \\mathbb{E}[y_{ij}|r_1,\\cdots,r_n;\\hat{r}_k] = \\frac{1}{1 + 10^{-(r_i - r_j + \\hat{r}_k x_k) / 2\\beta}}, \\end{equation} $$ where \\(\\hat{r}_k\\) denote the \"ratings\" of the additional regressors and \\(x_k\\) is the value of the additional regressors for the game. The update method for the entities remains unchanged, i.e. given by (3) from Elo as Logistic Regression, except we now also condition the expectation on the additional regressors. The update method for the additional regressors is given by</p> \\[ \\begin{equation} \\hat{r}^\\prime_k=\\hat{r}_k + k \\left(y_{ij} - \\mathbb{E}[y_{ij}|r_1,\\cdots,r_n;\\hat{r}_k]\\right)x_k. \\end{equation} \\] <p>It is often useful to specify a different k-factor/step-size for the additional regressors than for the entities, as the variance can be quite different for the additional regressors. Equivalently, we could scale our regressors appropriately before passing the data to the rating system. For convenience <code>elo-grad</code> allows the specification of different k-factors for the additional regressors (see Example).</p>"},{"location":"feature_ref/additional_regressors/#example","title":"Example","text":"<pre><code>from elo_grad import EloEstimator, Regressor\n\n# Input DataFrame with sorted index of Unix timestamps\n# and columns entity_1 | entity_2 | score | home\n# where score = 1 if player_1 won and score = 0 if\n# player_2 won. In all games, entity_1 has home\n# advantage, so home = 1 for all rows.\nhome_col = \"home\"\ndf = ...\nestimator = EloEstimator(\n    k_factor=20, \n    default_init_rating=1200,\n    entity_cols=(\"player_1\", \"player_2\"),\n    score_col=\"result\",\n    # Set the initial rating for home advantage to 0\n    init_ratings={home_col: (None, 0)},  \n    # Set k-factor/step-size to 1 for the home advantage regressor\n    additional_regressors=[Regressor(name=home_col, k_factor=1)],\n)\n# Get expected scores\nexpected_scores = estimator.predict_proba(df)\n# Get final ratings (of form (Unix timestamp, rating)) for home advantage\nratings = estimator.model.ratings[home_col]\n</code></pre>"},{"location":"feature_ref/additional_regressors/#other-approaches","title":"Other Approaches","text":"<p>The Elo rating system is the basis for 538's NFL predictions. There are a number of differences in their approach - notably they incorporate margin of victory.</p> <p>Focusing on regressors, they include additional regressors such as home advantage and rest adjustment, although these are fixed rather than fitted values. Interestingly, they also include a play-off adjustment factor which multiplies the rating difference. To include such a factor, we would need to allow interaction terms between a play-off flag and the entities  (see Roadmap).</p>"}]}